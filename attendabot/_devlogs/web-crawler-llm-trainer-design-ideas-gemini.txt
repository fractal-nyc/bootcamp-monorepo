PROMPT
I want to prep for senior software engineering interviews. one of those kind of interviews is the system design interview. i want you to help me design a 2-part practice question. PArt 1 is designing a web crawler. Part 2 is about designing an LLM training pipeline based on the websites crawled by the crawler in part 1. Let’s make a markdown file that defines a model solution to the two problems. It could be used as a rubric to grade someone’s performance on an interview. The solution should include functional and non-functional requirements like in a typical . Assume we’re operating at web scale (millions if not billions of users). We should note tradeoffs in the design and why we favor one approach vs another (usually tied to some part of the user experience or if not that a technical requirement). do deep research to create the best artifact


RESPONSE
Here is a comprehensive, senior-level rubric and model solution designed for evaluating a candidate on this two-part system design interview.System Design Interview Rubric: Web Crawler & LLM Training PipelineOverviewThis two-part interview tests a candidate's ability to navigate the full lifecycle of data at a massive scale: first by designing a distributed system to ingest the internet, and second by designing a compute-heavy pipeline to process that data into machine intelligence.At "web scale," the system will process billions of web pages (generating petabytes of raw text) and utilize tens of thousands of GPUs for training.Part 1: Distributed Web CrawlerProblem Statement: Design a web crawler that fetches billions of pages to build a text corpus.1. Requirements & Back-of-the-Envelope MathFunctional Requirements:Given a set of seed URLs, discover, fetch, and extract text and out-links from web pages.Store extracted text for downstream LLM processing.Track crawled URLs to prevent infinite loops.Non-Functional Requirements:Scale: 10 billion pages.Politeness: Must adhere to robots.txt and not DDoS target domains.Fault Tolerance: Crawler nodes will crash; the system must resume gracefully.Scale Estimations:10 Billion pages * ~2MB per page (HTML/Text) = 20 Petabytes of raw storage.To crawl this in 30 days: ~4,000 pages/second fetch rate.2. High-Level ArchitectureA senior candidate should construct a pipeline consisting of the following:URL Frontier (Scheduler): A priority queue that dictates which URLs to fetch next, ensuring domain-politeness and priority scheduling.DNS Cache: A custom DNS resolver to cache IP addresses (DNS resolution is a massive bottleneck in crawling).HTML Fetcher: Distributed worker nodes that download web pages using the IPs.Extractor & Parser: Extracts raw text (for the LLM) and new URLs (to feed back to the Frontier).Deduplication Service: Checks if the content or URL has already been processed.Storage: Blob storage (like Amazon S3 or HDFS) for raw text, and a NoSQL/Key-Value store for URL metadata and the "URL Seen" list.3. Key Tradeoffs & Deep Dives (Evaluation Focus)ComponentTradeoff / Decision PointThe "Senior" ApproachURL FrontierIn-memory vs. Disk-backed: 10B URLs will not fit in RAM.Uses a hybrid approach. Disks (e.g., Kafka or SQS) store the massive backlog, while in-memory queues pull small batches per domain to enforce rate-limiting and politeness.DeduplicationExact Match vs. Near-Duplicate: Web pages often have the same content but different timestamps or ads.Identifies that MinHash or SimHash is required for near-duplicate detection. Exact hashing (SHA-256) is insufficient and will ruin the LLM with duplicate data.TraversalBFS vs. DFS: How do we explore the web graph?Recommends Breadth-First Search (BFS). DFS can easily get trapped in infinite "spider traps" (e.g., dynamically generated calendars) and heavily overloads a single domain.Part 2: LLM Training PipelineProblem Statement: Take the petabytes of raw text gathered in Part 1 and design a pipeline to pre-train a massive Large Language Model (e.g., 100B+ parameters).1. Requirements & Back-of-the-Envelope MathFunctional Requirements:Ingest, clean, and tokenize raw crawler data.Train a transformer-based language model on the processed tokens.Periodically save model state (checkpointing).Non-Functional Requirements:Compute Scale: Training requires orchestrating 10,000+ GPUs.Throughput (MFU): Maximize GPU utilization; minimize idle time waiting for data or network transfers.Resilience: In a cluster of 10,000 GPUs, hardware failures are a daily occurrence. The pipeline cannot restart from scratch.Scale Estimations:A 100B parameter model requires ~200GB of memory just to store the weights (at 16-bit precision), plus optimizer states and gradients. It cannot fit on a single GPU.2. High-Level ArchitectureA senior candidate should break the system into two distinct phases:Phase A: Data Preparation Pipeline (CPU-Heavy)Quality Filtering: Removing boilerplate, non-language text, and low-quality data (crucial for model intelligence).PII Removal: Scrubbing sensitive information.Tokenization: Converting text to integer IDs using BPE (Byte-Pair Encoding) and storing them in optimized formats like TFRecord or Parquet.Phase B: Distributed Training Cluster (GPU-Heavy)Data Loader: Streams tokenized batches from distributed storage to GPU memory.Training Loop: Forward pass, loss calculation, backward pass, optimizer step.Checkpoint Manager: Asynchronously saves weights and optimizer states to persistent blob storage.3. Key Tradeoffs & Deep Dives (Evaluation Focus)ComponentTradeoff / Decision PointThe "Senior" ApproachModel DistributionData vs. Tensor vs. Pipeline Parallelism: How to split the workload.Explains 3D Parallelism. Data Parallelism (DP) copies the model, but since the model is too big, we need Tensor Parallelism (TP) to split individual layers across tightly coupled GPUs (NVLink), and Pipeline Parallelism (PP) to split sequential layers across different nodes.Data FilteringHeuristics vs. ML Classifiers: How to determine data "quality."Suggests a staged approach. Cheap heuristics (word count, symbol ratio) drop the obvious garbage first to save compute, followed by a smaller, faster classifier model to score and filter the remaining text.CheckpointingSynchronous vs. Asynchronous: Saving a 200GB+ model state to S3 takes time.Recommends Asynchronous Checkpointing to prevent GPUs from sitting idle while waiting for network I/O. Also mentions keeping the last $N$ checkpoints to handle corrupted saves.Overall Evaluation RubricUse the following criteria to score the candidate's overall performance:Strong Hire: The candidate seamlessly connects Part 1 and Part 2. They recognize that the decisions made in the crawler (like using MinHash for deduplication) directly impact the quality of the LLM. They naturally transition from standard distributed system concepts (queues, databases) to high-performance computing concepts (NVLink, 3D parallelism, GPU memory constraints) without needing heavy prompting. They proactively discuss fault tolerance in both environments.Hire: The candidate successfully designs both systems independently. They understand basic web crawling concepts (Frontier, Politeness) and grasp the necessity of splitting the LLM model across multiple GPUs (basic understanding of Data and Tensor parallelism). They may need slight prodding to handle edge cases like spider traps or daily GPU failures.No Hire: The candidate struggles with the sheer scale of the problem. They design a crawler that stores all state in RAM or fails to respect robots.txt. For the LLM, they treat training as a "black box" machine learning script rather than a distributed systems challenge, failing to account for how a 100B parameter model actually fits into memory or how to handle hardware node failures.Would you like to do a mock interview run-through where I act as the candidate and you ask me questions based on this rubric?